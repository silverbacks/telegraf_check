[global_tags]
  # Environment tag to identify the environment (e.g., production, staging)
  env = "production"
  
  # Region tag to identify the Azure region
  region = "azure"

[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  metric_batch_size = 1000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many hosts collecting at the same time.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  flush_jitter = "0s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  precision = ""

  ## Log at debug level.
  debug = false
  
  ## Log only error level messages.
  quiet = false
  
  ## Log file name, the empty string means to log to stderr.
  logfile = ""

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0s, the logfile does not get rotated based on time.
  logfile_rotation_interval = "0d"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0, the logfile does not get rotated based on size.
  logfile_rotation_max_size = "0MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  logfile_rotation_local = true

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

# INPUT PLUGINS
# System metrics for RHEL 7 & 8
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics.
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states.
  report_active = false

[[inputs.mem]]
  # no configuration

[[inputs.disk]]
  ## By default stats will be gathered for all mount points.
  ## Set mount_points will restrict the stats to only the specified mount points.
  # mount_points = ["/"]

  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

[[inputs.diskio]]
  # no configuration

[[inputs.net]]
  # no configuration

[[inputs.netstat]]
  # no configuration

[[inputs.linux_sysctl_fs]]
  # no configuration

[[inputs.processes]]
  # no configuration

[[inputs.system]]
  # no configuration

[[inputs.swap]]
  # no configuration

[[inputs.kernel]]
  # no configuration

[[inputs.kernel_vmstat]]
  # no configuration

# Azure VM specific metrics
[[inputs.cloudwatch]]
  region = "us-east-1"
  access_key = ""
  secret_key = ""
  token = ""
  role_arn = ""
  profile = ""
  shared_credential_file = ""
  token_file = ""
  endpoint_url = ""
  
  # Collect Azure VM metrics through CloudWatch if available
  period = "5m"
  delay = "5m"
  interval = "5m"
  cache_ttl = "10m"
  
  namespaces = ["Azure/VM"]
  
  [[inputs.cloudwatch.metrics]]
    names = ["CPUUtilization", "NetworkIn", "NetworkOut", "DiskReadOps", "DiskWriteOps"]
    
    [[inputs.cloudwatch.metrics.dimensions]]
      name = "InstanceId"
      value = "*"

# Azure Event Hub input for freeze events
[[inputs.eventhub_consumer]]
  ## The default behavior is to use a single partition consumer group.
  connection_string = "Endpoint=sb://your-namespace.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=your-shared-access-key"
  consumer_group = "$Default"
  partition_ids = ["0", "1", "2", "3"]
  eventhub_name = "azure-vm-events"
  
  ## Set the offset. The first time a consumer connects it will start:
  ##   at the beginning of the oldest retained event if set to "oldest"
  ##   at the end of the event stream if set to "newest"
  ##
  ## After the first connection the checkpoint will be stored in the
  ## configured database and on subsequent connections the consumer will
  ## resume at the checkpoint.
  offset = "oldest"

# Internal plugin to monitor Telegraf itself
[[inputs.internal]]
  ## Collect statistics about the telegraf agent
  collect_memstats = true

# Custom heartbeat with system information
[[inputs.exec]]
  commands = [
    "echo \"telegraf_heartbeat,host=$(hostname) status=1i,uptime=$(uptime | awk '{print $3}' | sed 's/,//')\""
  ]
  data_format = "influx"
  interval = "60s"

# Monitor Telegraf process itself
[[inputs.procstat]]
  pattern = "telegraf"
  pid_tag = true

# File-based heartbeat
[[inputs.file]]
  files = ["/tmp/telegraf_heartbeat"]
  data_format = "value"
  data_type = "integer"
  name_override = "telegraf_heartbeat_file"

# Exec-based heartbeat using our script
[[inputs.exec]]
  commands = ["/Users/christinejoylulu/workspace/telegraf_check/scripts/heartbeat.sh"]
  data_format = "influx"
  interval = "30s"

# OUTPUT PLUGINS
# HTTP output for sending metrics to a remote system
[[outputs.http]]
  ## URL is the address to send metrics to
  url = "https://prometheus-us-central1.grafana.net/api/prom/push"
  
  ## Timeout for HTTP message
  timeout = "5s"
  
  ## HTTP method, one of: "POST" or "PUT"
  method = "POST"
  
  ## HTTP Basic Auth credentials
  username = "your-prometheus-username"
  password = "your-prometheus-api-key"
  
  ## Optional TLS Config
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  ## Use TLS but skip chain & host verification
  # insecure_skip_verify = false
  
  ## Data format to output.
  data_format = "prometheusremotewrite"
  
  [outputs.http.headers]
    Content-Type = "application/x-protobuf"
    Content-Encoding = "snappy"
    X-Prometheus-Remote-Write-Version = "0.1.0"